name: Micro benchmarks

on:
  pull_request:
    types: [opened, synchronize, labeled]
    branches:
      - main
  push:
    branches:
      - "**"
 
jobs:
  Micro-benchmarks:
    name: Criterion Benchmarks
    if: contains(github.event.pull_request.labels.*.name, 'benchmark') || contains(github.event.head_commit.message, 'benchmark')
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v2

      - name: Install Critcmp
        run: cargo install critcmp || echo "Critcmp is already installed"

      - name: Benchmark changes
        run: |
          cargo bench --bench impl_path_string_for_evaluation_context -- --save-baseline new_branch
          cargo bench --bench data_loader_bench -- --save-baseline new_branch
          cargo bench --bench request_template_bench -- --save-baseline new_branch
          cargo bench --bench json_like_bench -- --save-baseline new_branch

      - name: Fetch base branch
        run: git fetch

      - name: Checkout base branch
        run: git checkout ${{ github.base_ref }}

      - name: Benchmark base
        run: |
          cargo bench --bench impl_path_string_for_evaluation_context -- --save-baseline main_branch
          cargo bench --bench data_loader_bench -- --save-baseline main_branch
          cargo bench --bench request_template_bench -- --save-baseline main_branch
          cargo bench --bench json_like_bench -- --save-baseline main_branch

      - name: Run shell script
        run: |
          chmod +x .github/scripts/check_degradation.sh
          bash .github/scripts/check_degradation.sh
          
      - name: Create empty output file
        run: touch output_file.txt

      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '14'

      - name: Install dependencies
        run: npm install

      - name: Run GitHub Script
        uses: actions/github-script@v6
        with:
          script: |
            const fs = require('fs');
            const fileContent = fs.readFileSync('output_file.txt', 'utf8');
            const scriptContext = github.context;
            const issue_number = scriptContext.payload.issue?.number || scriptContext.payload.pull_request?.number;

            console.log(`Issue Number: ${issue_number}`); // Add this line for logging

            const comment = `
            <details>
            <summary>Benchmark Results</summary>
            | Test                  | Base     | PR           | % change |
            |-------------------------------|--------------|------------------|------------|
            ${fileContent}
            </details>
            `;

            github.rest.issues.createComment({
              owner: scriptContext.repo.owner,
              repo: scriptContext.repo.repo,
              issue_number: issue_number,
              body: comment
            });
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}


  Build_time_compare:
    if: contains(github.event.pull_request.labels.*.name, 'benchmark') || contains(github.event.head_commit.message, 'benchmark')
    name: iai_callgrind_benchmarks
    runs-on: ubuntu-latest

    steps:
      - name: Checkout the code from the repository
        uses: actions/checkout@v2

      - name: Install iai-callgrind-runner
        run: cargo install --version 0.7.3 iai-callgrind-runner

      - name: Install Valgrind
        run: sudo apt-get update && sudo apt-get install valgrind

      - name: Execute build_time_compare.sh
        run: |
          chmod +x .github/scripts/compare_build_time.sh
          bash .github/scripts/compare_build_time.sh
